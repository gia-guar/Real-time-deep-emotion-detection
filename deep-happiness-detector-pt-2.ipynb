{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518c4149",
   "metadata": {
    "papermill": {
     "duration": 0.003469,
     "end_time": "2022-09-19T22:18:24.046759",
     "exception": false,
     "start_time": "2022-09-19T22:18:24.043290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DEEP HAPPINESS DETECTOR PT. 2\n",
    "## building an ensemble \n",
    "go check pt 1 here: https://www.kaggle.com/gianmarcoguarnier/deep-happiness-detector-pt-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0756809",
   "metadata": {
    "papermill": {
     "duration": 0.00234,
     "end_time": "2022-09-19T22:18:24.051721",
     "exception": false,
     "start_time": "2022-09-19T22:18:24.049381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After having built a single binary classificator in part 1 we can move to part 2: <br>\n",
    "In this section we are going to train an **ensemble classifcator** where each voter is a binary classificator. <br>\n",
    "We can use a global variable to train 5 binary classificators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8340de66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T22:18:24.058670Z",
     "iopub.status.busy": "2022-09-19T22:18:24.057990Z",
     "iopub.status.idle": "2022-09-19T22:18:30.207973Z",
     "shell.execute_reply": "2022-09-19T22:18:30.206994Z"
    },
    "papermill": {
     "duration": 6.156249,
     "end_time": "2022-09-19T22:18:30.210479",
     "exception": false,
     "start_time": "2022-09-19T22:18:24.054230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D,Input\n",
    "from keras.models import Model,Sequential \n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85592866",
   "metadata": {
    "papermill": {
     "duration": 0.002343,
     "end_time": "2022-09-19T22:18:30.215650",
     "exception": false,
     "start_time": "2022-09-19T22:18:30.213307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aaf1d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T22:18:30.222117Z",
     "iopub.status.busy": "2022-09-19T22:18:30.221570Z",
     "iopub.status.idle": "2022-09-19T22:18:30.226126Z",
     "shell.execute_reply": "2022-09-19T22:18:30.225135Z"
    },
    "papermill": {
     "duration": 0.009874,
     "end_time": "2022-09-19T22:18:30.228054",
     "exception": false,
     "start_time": "2022-09-19T22:18:30.218180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '../input/face-expression-recognition-dataset/images/train'\n",
    "valid_path = '../input/face-expression-recognition-dataset/images/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf21820",
   "metadata": {
    "papermill": {
     "duration": 0.002269,
     "end_time": "2022-09-19T22:18:30.232767",
     "exception": false,
     "start_time": "2022-09-19T22:18:30.230498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Original images are sized 48x48 pixels. The resolution is pretty bad. We can up-sample to 256x256 by uploading the data with<br>\n",
    "tf.keras.utils.image_from_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504b775e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T22:18:30.238719Z",
     "iopub.status.busy": "2022-09-19T22:18:30.238444Z",
     "iopub.status.idle": "2022-09-19T22:18:55.622925Z",
     "shell.execute_reply": "2022-09-19T22:18:55.622037Z"
    },
    "papermill": {
     "duration": 25.389787,
     "end_time": "2022-09-19T22:18:55.624987",
     "exception": false,
     "start_time": "2022-09-19T22:18:30.235200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 22:18:50.282376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:50.379601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:50.380394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:50.389861: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-19 22:18:50.390136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:50.390875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:50.391497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:52.516645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:52.517526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:52.518196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 22:18:52.518775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 files belonging to 7 classes.\n",
      "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = tf.keras.utils.image_dataset_from_directory(train_path)    \n",
    "VALID = tf.keras.utils.image_dataset_from_directory(valid_path)    \n",
    "print(TRAIN)\n",
    "\n",
    "TRAIN_unbatched = TRAIN.unbatch()\n",
    "VALID_unbatched = VALID.unbatch()\n",
    "\n",
    "import gc\n",
    "del TRAIN,VALID\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e5563",
   "metadata": {
    "papermill": {
     "duration": 0.002695,
     "end_time": "2022-09-19T22:18:55.630804",
     "exception": false,
     "start_time": "2022-09-19T22:18:55.628109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## function the needs to be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cc47f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T22:18:55.638773Z",
     "iopub.status.busy": "2022-09-19T22:18:55.637352Z",
     "iopub.status.idle": "2022-09-19T22:18:55.644182Z",
     "shell.execute_reply": "2022-09-19T22:18:55.643330Z"
    },
    "papermill": {
     "duration": 0.012381,
     "end_time": "2022-09-19T22:18:55.646109",
     "exception": false,
     "start_time": "2022-09-19T22:18:55.633728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_labl(x,y):\n",
    "    label = np.int32(-1)\n",
    "    if y==keep[0]: label = np.int32(1)\n",
    "    if y==keep[1]: label = np.int32(0)    \n",
    "    return x,label\n",
    "\n",
    "def drop_extra_classes(x,y):\n",
    "        if y == keep[0]: return True\n",
    "        if y == keep[1]: return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d068c",
   "metadata": {
    "papermill": {
     "duration": 0.002785,
     "end_time": "2022-09-19T22:18:55.651619",
     "exception": false,
     "start_time": "2022-09-19T22:18:55.648834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and saving 5 models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de1dce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T22:03:11.398370Z",
     "iopub.status.busy": "2022-09-19T22:03:11.397939Z",
     "iopub.status.idle": "2022-09-19T22:17:57.322665Z",
     "shell.execute_reply": "2022-09-19T22:17:57.318903Z",
     "shell.execute_reply.started": "2022-09-19T22:03:11.398337Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-09-19T22:18:55.654395",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {0:'angry', 1:'disgust', 2:'fear', 3:'happy', 4:'neutral', 5:'sad',6:'surprise'}\n",
    "fig, ax = plt.subplots(ncols= 3, nrows=3)\n",
    "for i in range(6):\n",
    "    \n",
    "    keep = [3,2]\n",
    "    \n",
    "    train = TRAIN_unbatched.filter(drop_extra_classes)\n",
    "    valid = VALID_unbatched.filter(drop_extra_classes)\n",
    "    \n",
    "    # normalizing...\n",
    "    train = train.map(lambda x,y: (x/255,y))\n",
    "    valid = valid.map(lambda x,y: (x/255,y))\n",
    "    \n",
    "    # rename label to 1-0\n",
    "    def rename_labl(x,y):\n",
    "        label = np.int32(-1)\n",
    "        if y==keep[0]: label = np.int32(1)\n",
    "        if y==keep[1]: label = np.int32(0)    \n",
    "        return x,label\n",
    "    \n",
    "    # batch back up\n",
    "    train = train.batch(batch_size = 50)\n",
    "    valid = valid.batch(batch_size = 50)\n",
    "    \n",
    "    # model init\n",
    "    model = Sequential()\n",
    "\n",
    "    #1st CNN layer\n",
    "    model.add(Conv2D(64, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #2nd CNN layer\n",
    "    model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Dropout (0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Fully connected 1st layer\n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #Fully connected 2st layer\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    # Regularization\n",
    "    logdir='logs'\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,verbose=0,min_delta=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "    \n",
    "    hist = model.fit(train, verbose=0, epochs=50, validation_data=valid, callbacks=[tensorboard_callback,reduce_learningrate, early_stopping])\n",
    "    \n",
    "    # visualize training overview\n",
    "    ax[i].title(labels[i])\n",
    "    ax[i].ylabel('Accuracy', fontsize=16)\n",
    "    ax[i].xlabel('Epochs',fontsize=16)\n",
    "    ax[i].plot(hist.history['accuracy'], label='Training Accuracy')\n",
    "    ax[i].plot(hist.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax[i].legend(loc='lower right')\n",
    "    print(labels[i]+\" vs happy: trained (val. acc. = \"+history['val_accuracy'][-1]+\")\")\n",
    "    modelname = \"from_\" + labels[keep[1]]+\"_to_\"+labels[keep[0]]+\".h5\"\n",
    "    model.save(modelname)\n",
    "    print(modelname,\"Saved\")\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-19T22:18:16.475775",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}